{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boilerplate\n",
    "%matplotlib inline\n",
    "\n",
    "# Intel DAAL related imports\n",
    "from daal.data_management import (\n",
    "    DataSourceIface, FileDataSource, HomogenNumericTable, CSRNumericTable, NumericTable, BlockDescriptor\n",
    ")\n",
    "\n",
    "\n",
    "from utils import createSparseTable\n",
    "\n",
    "# Import numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting configurations\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Multinomial Naive Bayes\n",
    "\n",
    "### Tutorial brief\n",
    "This tutorial is an example of using Naive Bayes algorithms from pyDAAL to build predictive models.\n",
    "We use the well-studied 20 Newsgroups dataset to train Multinomial Naive Bayes model in online processing mode. We  test the accuracy of the model using quality metrics for multi-class classification. The code for Multinomial Naive Bayes model training and prediction is provided partially. You are required to fill in the gaps.\n",
    "\n",
    "### Learning objectives\n",
    "* To understand how to process the sparse data that doen not fit into memory using online computing mode. \n",
    "* To understand and practice the typical code sequence of using pyDAAL for classification.\n",
    "* To understand how to measuring the quality of the trained model.\n",
    "\n",
    "\n",
    "### Multinomial Naive Bayes introduction\n",
    "Supervised learning involves training a model using the data that has known responses, and then apply the model to predict responses for unseen data. In the case of **Multinomial Naive Bayes** classifier, the model is probabilistic.\n",
    "\n",
    "Let $J$ be the number of classes, indexed $k = 0, 1, \\ldots, J-1$. The feature vector $x_i = (x_{i1}, \\ldots, x_{ip})$, $i = 1, \\ldots, n$, contains scaled frequencies: the value of $x_{ij}$ is the frequency of the $j$-th feature is observed in the vector $x_i$. In terms of the document classification problem, $x_{ij}$ is the frequency of occurrence of the word indexed $j$ in the document $x_i$.\n",
    "The response $y_i$ is the index of the class, $y_i \\in {0, 1, \\ldots, J-1}$ corresponding to the document $x_i$.\n",
    "\n",
    "On the training stage the probability estimates of the occurense on the word $i$ in the document class $k$ are computed:\n",
    "$$log(\\theta_{ki}) = log\\bigg( \\frac{N_{ki} + \\alpha_k}{N_k + \\alpha}\\bigg)$$\n",
    "where\n",
    "$$N_{ki} = \\sum \\limits_{x: x \\in X, y(x) = k} x_i, N_k = \\sum \\limits_{i = 1}^m N_i$$\n",
    "\n",
    "On the prediction stage, given a new feature vector $x$ , the classifier determines the class the vector belongs to:\n",
    "$$y(x) = argmax_{k \\in \\{0, \\ldots, J-1\\}} \\Big(log(p(y=k)) + \\sum \\limits_{i} log(\\theta_{ki})\\Big)$$\n",
    "\n",
    "The details about the algorithm: [\"Tackling the Poor Assumptions of Naive Bayes Text Classifiers\" by Jason D. M. Rennie et al.](https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Newsgroups dataset\n",
    "The dataset has already been downloaded to the ./mldata folder. There are 11314 training and 7514 testing samples (documents) and 130107 features (words). Here's the detailed information about this dataset, including descriptions of each class:\n",
    "\n",
    "> Origin: \n",
    "\n",
    "> This dataset was collected in the School of Computer Science, Carnegie Mellon University. \n",
    "\n",
    "> Creator: \n",
    "\n",
    "> Tom Mitchell\n",
    "\n",
    "> Data Set Information:\n",
    "\n",
    "> Concerns 18828 messages from 20 newsgroups.\n",
    "\n",
    "> Information about classes:\n",
    "\n",
    "> 1.  alt.atheism\n",
    "> 2.  comp.graphics\n",
    "> 3.  comp.os.ms-windows.misc\n",
    "> 4.  comp.sys.ibm.pc.hardware\n",
    "> 5.  comp.sys.mac.hardware\n",
    "> 6.  comp.windows.x\n",
    "> 7.  misc.forsale\n",
    "> 8.  rec.autos\n",
    "> 9.  rec.motorcycles\n",
    "> 10. rec.sport.baseball\n",
    "> 11. rec.sport.hockey\n",
    "> 12. sci.crypt\n",
    "> 13. sci.electronics\n",
    "> 14. sci.med\n",
    "> 15. sci.space\n",
    "> 16. soc.religion.christian\n",
    "> 17. talk.politics.guns\n",
    "> 18. talk.politics.mideast\n",
    "> 19. talk.politics.misc\n",
    "> 20. talk.religion.misc\n",
    "\n",
    "> Words examples: archive, name, atheism, resources, alt, last, modified, december, version, atheist, addresses, of, organizations, usa, freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sparse numeric table from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def createSparseTable(file, nFeatures):\n",
    "    rowIdx = []\n",
    "    colIdx = []\n",
    "    data = []\n",
    "    with open(file, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in datareader:\n",
    "            rowIdx.append(int(row[0]))\n",
    "            colIdx.append(int(row[1]))\n",
    "            data.append(float(row[2]))\n",
    "\n",
    "    rowIdx = np.array(rowIdx)\n",
    "    rowIdx = rowIdx - rowIdx[0]\n",
    "\n",
    "    nObservations = rowIdx[len(data)-1] + 1\n",
    "    cooData = coo_matrix((data, (rowIdx, colIdx)), shape=(nObservations, nFeatures))\n",
    "    csrDara = cooData.tocsr()\n",
    "    table = CSRNumericTable(csrDara.data.astype(np.float64), csrDara.indices.astype(np.uint64) + 1, csrDara.indptr.astype(np.uint64) + 1,\n",
    "                            int(nFeatures), int(nObservations))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes model training on 20 Newsgroups dataset\n",
    "The training data is split into 5 blocks, ~2200 samples each. For each block of data the code below does following:\n",
    "- Reads the data in coordinate format from files `/mldata/20newsgroups.coo.<block>.csv` and creates a CSRNumericTable with training data (`xTrain`)\n",
    "- Reads the  ground truth into dense NumericTable (`yTrain`)\n",
    "- Updates the training result with a new block of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "from daal.algorithms import classifier\n",
    "from daal.algorithms.multinomial_naive_bayes import training as nb_training\n",
    "\n",
    "# Number of blocks of data in the training data set\n",
    "nBlocks = 5\n",
    "# Number of classes\n",
    "nClasses = 20\n",
    "# Number of words in the documents\n",
    "nFeatures = 130107\n",
    "\n",
    "# Create an algorithm object to train Multinomial Naive Bayes model in online processing mode\n",
    "nbTrain = nb_training.Online(nClasses, method=nb_training.fastCSR)\n",
    "\n",
    "for i in range(nBlocks):\n",
    "    # Load new block of data from CSV file\n",
    "    xTrain = createSparseTable('./mldata/20newsgroups.coo.' + str(i + 1) + '.csv', nFeatures)\n",
    "    # Load new block of labels from CSV file\n",
    "    labelsDataSource = FileDataSource(\n",
    "        './mldata/20newsgroups.labels.' + str(i + 1) + '.csv',\n",
    "        DataSourceIface.doAllocateNumericTable, DataSourceIface.doDictionaryFromContext\n",
    "    )\n",
    "    labelsDataSource.loadDataBlock()\n",
    "    yTrain = labelsDataSource.getNumericTable()\n",
    "    \n",
    "\n",
    "    # Set input\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    # There are two pieces of input to be set: data and labels. You should\n",
    "    # use the 'input.set' member methods of the nbTrain algorithm object.\n",
    "    # The input IDs to use are 'classifier.training.data' and 'classifier.training.labels'\n",
    "    # respectively.\n",
    "   \n",
    "\n",
    "    # Compute\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    # Call the 'compute()' method of your algorithm object to update the partial model.\n",
    "\n",
    "model = nbTrain.finalizeCompute().get(classifier.training.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with Multinomial Naive Bayes model\n",
    "\n",
    "The code below gets the training data from `sklearn` 20 Newsgroups dataset and creates 2 NumericTables: test data in CSR format (xTest) and test ground truth (yTest). We use Multinomial Naive Bayes prediction algorithm and the model obtained on the training stage to compute the predictions for a new, prevoiusly unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1318\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 936\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ed2c1fa4509f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdaal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial_naive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnb_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnewsgroups_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_20newsgroups_vectorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewsgroups_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36mfetch_20newsgroups_vectorized\u001b[1;34m(subset, remove, data_home)\u001b[0m\n\u001b[0;32m    336\u001b[0m                                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m                                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                                     remove=remove)\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     data_test = fetch_20newsgroups(data_home=data_home,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36mfetch_20newsgroups\u001b[1;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing)\u001b[0m\n\u001b[0;32m    223\u001b[0m                         \"This may take a few minutes.\")\n\u001b[0;32m    224\u001b[0m             cache = download_20newsgroups(target_dir=twenty_home,\n\u001b[1;32m--> 225\u001b[1;33m                                           cache_path=cache_path)\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'20Newsgroups dataset not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\site-packages\\sklearn\\datasets\\twenty_newsgroups.py\u001b[0m in \u001b[0;36mdownload_20newsgroups\u001b[1;34m(target_dir, cache_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Downloading dataset from %s (14 MB)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 544\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\prod_daal_2018\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "from daal.algorithms.multinomial_naive_bayes import prediction as nb_prediction\n",
    "\n",
    "newsgroups_test = ds.fetch_20newsgroups_vectorized(subset='test')\n",
    "\n",
    "testData = newsgroups_test.data\n",
    "\n",
    "xTest = CSRNumericTable(testData.data.astype(np.float64), testData.indices.astype(np.uint64) + 1, testData.indptr.astype(np.uint64) + 1,\n",
    "                        int(testData.shape[1]), int(testData.shape[0]))\n",
    "yTest = newsgroups_test.target\n",
    "\n",
    "# Create an algorithm object to predict Multinomial Naive Bayes values\n",
    "nbTest = nb_prediction.Batch(nClasses, method=nb_prediction.fastCSR)\n",
    "\n",
    "# Pass a testing data set and the trained model to the algorithm\n",
    "nbTest.input.setTable(classifier.prediction.data,  xTest)\n",
    "nbTest.input.setModel(classifier.prediction.model, model)\n",
    "\n",
    "# Compute\n",
    "predictions = nbTest.compute().get(classifier.prediction.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the confusion matrix\n",
    "To see if the model has done a good job, we print the confusion matrix.\n",
    "\n",
    "|                |           ||            Predicted Class             ||\n",
    "| -------------- | --------- | --------- | --------- | ---- | --------- |\n",
    "|                |           |  ** 1 **  |  ** 2 **  |  ... |  ** J **  |\n",
    "|                |  ** 1 **  |  $n_{11}$ |  $n_{12}$ |  ... |  $n_{1J}$ |\n",
    "|**Actual Class**|  ** 2 **  |  $n_{21}$ |  $n_{22}$ |  ... |  $n_{2J}$ |\n",
    "|                |    ...    |    ...    |    ...    |  ... |    ...    |\n",
    "|                |  ** J **  |  $n_{J1}$ |  $n_{J2}$ |  ... |  $n_{JJ}$ |\n",
    "\n",
    "Here $n_{ij}$ is the number of samples that belong to actual class $i$, and predicted as the class $j$.\n",
    "\n",
    "If the model does a perfect job then the diagonal elements of the matrix will dominate. As we'll see, it's not quite the case. But still the predictions are close to true values in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from daal.algorithms.multi_class_classifier import quality_metric_set\n",
    "from daal.algorithms.classifier.quality_metric import multiclass_confusion_matrix\n",
    "from daal.data_management import BlockDescriptor, readOnly\n",
    "\n",
    "qualityMetricSet = quality_metric_set.Batch(nClasses)\n",
    "input = qualityMetricSet.getInputDataCollection().getInput(quality_metric_set.confusionMatrix)\n",
    "\n",
    "yTest2d = yTest.reshape(yTest.size, 1)\n",
    "groundTruth = HomogenNumericTable(yTest2d.astype(np.float64))\n",
    "input.set(multiclass_confusion_matrix.predictedLabels,   predictions)\n",
    "input.set(multiclass_confusion_matrix.groundTruthLabels, groundTruth)\n",
    "\n",
    "# Compute quality metrics and get the quality metrics\n",
    "# returns ResultCollection class from daal.algorithms.multi_class_classifier.quality_metric_set\n",
    "qualityMetricResult = qualityMetricSet.compute().getResult(quality_metric_set.confusionMatrix)\n",
    "confusionMatrix = qualityMetricResult.get(multiclass_confusion_matrix.confusionMatrix)\n",
    "\n",
    "bd = BlockDescriptor()\n",
    "nrows = confusionMatrix.getNumberOfRows()\n",
    "confusionMatrix.getBlockOfRows(0, nrows, readOnly, bd)\n",
    "npa = np.copy(bd.getArray())\n",
    "print(npa)\n",
    "confusionMatrix.releaseBlockOfRows(bd)\n",
    "\n",
    "qualityMetricsTable = qualityMetricResult.get(multiclass_confusion_matrix.multiClassMetrics)\n",
    "qualityMetricsTable.getBlockOfRows(0, 1, readOnly, bd)\n",
    "qualityMetricsData = bd.getArray().flatten()\n",
    "print(\"Average accuracy: {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.averageAccuracy]))\n",
    "print(\"Error rate:       {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.errorRate]))\n",
    "print(\"Micro precision:  {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microPrecision]))\n",
    "print(\"Micro recall:     {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microRecall]))\n",
    "print(\"Micro F-score:    {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.microFscore]))\n",
    "print(\"Macro precision:  {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroPrecision]))\n",
    "print(\"Macro recall:     {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroRecall]))\n",
    "print(\"Macro F-score:    {0:.3f}\".format(qualityMetricsData[multiclass_confusion_matrix.macroFscore]))\n",
    "qualityMetricsTable.releaseBlockOfRows(bd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this lab, we learned a widely used algorithm for documents classification: Multinomial Naive Bayes. We saw how to apply it to the 20 Newsgroups dataset. We studied and practiced pyDAAL API for this algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
